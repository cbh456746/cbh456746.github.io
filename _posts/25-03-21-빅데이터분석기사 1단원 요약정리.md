---
layout:     post
title:      "빅데이터분석기사 1단원 요약정리"
subtitle:   "post_subtitle"
date:       2025-03-21 12:00:00
author:     "BH CHOI"
header-img: "img/post-bg-2015.jpg"
catalog: true
mathjax: true
tags:
    - Data Science
---
# 빅데이터 분석 기획

## 빅데이터 개요 및 활용

### 빅데이터 활용을 위한 3대 요소
- 인력, 자원, 기술 (인자기)

### 빅데이터의 특징 (3V, 5V)
- Volume : 데이터의 양
- Variety : 데이터의 다양성(정형, 비정형, 반정형)
- Velocity : 데이터 생성 및 처리 속도 (실시간성)
- Value : 데이터로부터 얻는 가치
- Veracity : 데이터의 신뢰성, 정확성

### DIKW 피라미드
- 데이터 → 정보 → 지식 → 지혜

### 암묵지, 형식지
- 암묵지 : 개인에게 습득되고 겉으로 드러나지 않은 지식
- 형식지 : 문서, 매뉴얼 등 형태로 명시화된 지식

### 데이터베이스의 개념
1) DB : 일정 구조에 맞게 조직화된 데이터의 집합.
	- 스키마 : 데이터 구조를 정의한 설계도
	- 인스턴스 : 데이터베이스의 특정 시점에서의 데이터 내용
	- 메타데이터 : 데이터를 설명하는 데이터(데이터에 대한 정보)
	- 인덱스 : 데이터 검색 속도 향상을 위한 자료구조

2) DBMS : DB를 관리, 접근 환경을 제공하는 소프트웨어
	- 관계형 DBMS : 테이블 형태로 정리
	- NoSQL : 비정형 데이터를 저장하고 처리 (Not only SQL)
	
3) SQL : 데이터베이스에 접근 가능한 구조적 질의 언어

4) 데이터베이스의 특징 : 공용, 통합, 저장, 변화 (공통저변)

## 데이터 산업의 이해

### 데이터 산업의 발전
- 처리 → 통합 → 분석 → 연결 → 권리

### 데이터 사이언스
- 데이터 관련된 모든 분야의 전문지식을 종합한 학문
- 하드 & 소프트 스킬 
  - 하드 스킬 : 프로그래밍, 통계 분석 등 기술적 역량
  - 소프트 스킬 : 의사소통, 문제해결력 등 비기술적 역량

### Hadoop
- 여러 컴퓨터를 하나로 묶어 대용량 데이터를 처리하는 오픈소스 빅데이터 솔루션
1) 하둡 코어 프로젝트
- HDFS : 분산 파일 시스템으로 데이터 저장
- MapReduce : 병렬 처리를 통해 데이터 처리

2) 하둡 에코시스템
- YARN, Hive, Pig, HBase, Zookeeper, Spark 등 다양한 부가 프로젝트 포함

### 데이터 단위
- KB < MB < GB < TB < PB < EB < ZB < YB (피이지요)

## 빅데이터 조직 및 인력

### 조직 및 인력 방안
- 집중 구조 : 빅데이터 관련 업무를 중앙에서 집중 관리
- 기능 구조 : 기능별로 역할을 구분하여 관리
- 분산 구조 : 여러 부서에서 독립적으로 빅데이터 업무 수행

### 빅데이터 플랫폼
- 소프트웨어 : 데이터 분석 및 활용 소프트웨어
- 플랫폼 : 데이터 수집 및 관리 기능 제공
- 인프라스트럭처 : 하드웨어 및 네트워크 인프라 구성

## 빅데이터와 인공지능

### 머신러닝의 종류
- 지도학습 : 정답을 알려주고 학습
- 비지도학습 : 정답을 가르쳐주지 않고 학습
- 준지도학습 : 정답이 있는 데이터와 없는 데이터를 모두 활용
- 강화학습 : 에이전트가 환경에서 보상을 통해 행동을 학습

### 경량 딥러닝 학습 기법
- 전이학습 : 사전에 훈련된 모델을 다른 분야에 재사용
- Fine-tuning : 학습된 모델을 특정 문제에 맞게 재조정
- 지식증류 : 복잡한 Teacher Network를 간단한 Student Network로 압축

### 최신 기술동향
- AutoML : 자동화된 머신러닝 모델 설계 및 구축 기술
- MLOps : 머신러닝의 개발 및 운영을 통합 관리하는 체계
- XAI : 설명 가능한 AI, 모델의 예측 결과를 인간이 이해할 수 있도록 설명 제공
- Gen AI : 생성형 인공지능, 데이터를 기반으로 새로운 콘텐츠 생성

## 개인정보 법 제도

### 데이터 3법
- 개인정보 보호법
- 정보통신망법
- 신용정보법

### 데이터 3법 주요 특징
- 가명정보의 개념 도입
- 개인정보보호 거버넌스 체계 효율화
- 개인정보처리자 책임 강화
- 개인정보 판단기준 명확화

### 비식별조치 가이드라인
- 사전검토 → 비식별조치 → 적정성 평가 → 사후관리

## 데이터 분석 계획

### 데이터 분석 프로젝트 우선순위 선정 기준
- 시급성 관점 : 비즈니스 효과, KPI, Value
- 난이도 관점 : 투자비용 요소, Volume, Variety, Velocity

## 분석 문제 정의
- 하향식 접근 방법 : 경영진 중심 목표 설정 후 분석 과제 도출
- 상향식 접근 방법 : 현장 전문가와 실무자로부터 분석 과제 도출
- 혼합 접근 방법
  1) 발산 단계 : 다양한 의견과 아이디어 수렴
  2) 수렴 단계 : 효과적이고 실행 가능한 과제 선정

## 데이터 분석 방안

### 분석 방법론 구성요소
- 절차, 방법, 도구와 기능, 템플릿과 산출물

### 분석과제에서 고려해야 할 5가지 요소
- 데이터 크기, 속도, 데이터 복잡도, 분석 복잡도, 정확도/정밀도

### 분석 방법론 모델
- 계층적 프로세스 모델 : 상위 목표부터 하위 단계까지 세분화하여 진행
- 폭포수 모델 : 순차적 단계별 접근
- 나선형 모델 : 점진적이고 반복적 접근
- 프로토타입 모델 : 시제품 제작 후 개선
- 반복적 모델 : 단계별 반복적 개선
- 애자일 : 민첩하고 유연한 반복적 개발

### 분석 방법론
- KDD : 데이터베이스에서 지식 발견 프로세스
- Crisp-DM : 산업 표준 데이터 마이닝 프로세스
- SEMMA : SAS가 개발한 데이터 분석 방법론 (Sample, Explore, Modify, Model, Assess)

### 빅데이터 분석 방법론 
- Planning → Preparing → Analyzing → Developing → Deploying

### 데이터 분석 수준 진단
1) 분석 준비도 : 데이터, 조직, 프로세스, 인력, 문화, 기술(6가지 분석 구성요소)
2) 분석 성숙도 : CMMI 모델을 기반으로 조직의 데이터 분석 능력과 성숙도를 평가

### 데이터 거버넌스
- 전사차원에서 데이터에 대해 표준화된 관리 체계 수립

1) 구성요소 
	- 원칙: 데이터 관리 및 활용의 기본 원칙과 방향 제시
	- 조직: 데이터 관리 역할을 담당하는 조직과 책임 체계 구성
	- 프로세스: 데이터 관리 절차와 프로세스를 명확히 정의

2) 중요 관리 대상
	- 마스터 데이터: 비즈니스 전반에서 공통적으로 활용되는 기준 데이터
	- 메타데이터: 데이터를 설명하는 데이터
	- 데이터 사전: 데이터 용어 정의 및 데이터 간 관계 정리

- 데이터 거버넌스 체계
  1) 데이터 표준화: 데이터의 명칭, 형식, 정의 등의 통일성 확보
  2) 데이터 관리 체계: 데이터 생성부터 폐기까지 전 과정 관리
  3) 데이터 저장소 관리: 데이터의 안전하고 효율적인 저장 및 접근 관리
  4) 표준화 활동: 데이터 표준의 지속적 유지 관리 및 개선

# 데이터 수집 및 저장계획

## 데이터 수집

### 데이터 수집 기술
1) ETL : 데이터 추출(Extract), 변환(Transform), 적재(Load) 프로세스
2) FTP : 파일 전송 프로토콜로 원격지의 파일 전송
3) API : 응용 프로그램 간 데이터 교환 및 서비스 연동 인터페이스
4) Sqoop : Hadoop과 RDBMS 간 데이터 전송
5) Flume : 실시간 로그 및 이벤트 데이터를 수집하는 프레임워크
6) Crawling : 웹사이트의 데이터를 자동으로 수집

## 데이터 유형 및 속성 파악

### 데이터 유형
1) 정성적(질적 데이터), 정량적(양적 데이터)
2) 정형(구조화), 반정형(부분적 구조화), 비정형(구조 없음)
3) 가역(원상복구 가능), 불가역(원상복구 불가능)
4) 내부(조직 내부), 외부(외부 환경)

### 데이터의 척도 구분
1) 질적 척도
	- 명목 척도: 단순 분류 목적(예: 성별, 혈액형)
	- 순서 척도(서열 척도): 순서가 있는 범주형 데이터(예: 등급, 순위)

2) 양적 척도
	- 등간 척도: 일정한 간격을 가진 데이터(예: 온도)
	- 비율 척도: 절대적 0을 기준으로 하는 데이터(예: 키, 몸무게)

## 데이터 비식별화

### 개인정보 비식별화 기법
1) 가명처리: 개인 식별이 어렵도록 개인 정보를 변환
2) 총계처리: 데이터를 집계하여 개별 정보 식별 불가
3) 데이터 삭제: 민감 정보 또는 불필요한 데이터 삭제
4) 데이터 범주화: 데이터를 범주화하여 개별 정보 보호
5) 데이터 마스킹: 민감한 데이터를 숨기거나 변형하여 보호

### 프라이버시 보호 모델
1) k-익명성 : 특정 개인이 최소 k명 이상 동일한 정보로 식별 가능
2) l-다양성 : 민감 정보가 최소한 l가지 이상 다양성을 갖도록 보호
3) t-근접성: 비식별화 후에도 원본 데이터 분포와 유사하게 유지

## 데이터 품질 검증

### 데이터 품질 기준
1) 완전성 : 데이터가 누락 없이 모두 존재
2) 정확성 : 데이터가 실제 값과 정확히 일치
3) 일관성 : 데이터 간에 충돌이나 모순이 없음
4) 최신성 : 가장 최신 데이터를 반영
5) 유효성 : 데이터가 특정 규칙과 조건을 만족
6) 접근성 : 데이터 접근이 쉽고 빠르게 가능
7) 보안성 : 데이터를 외부의 위협으로부터 보호

### 데이터 품질 진단 및 개선 절차 
1) 진단 절차 : 진단 대상 정의 → 품질 진단 실시 → 진단 결과 분석
2) 개선 절차 : 개선 계획 수립 → 개선 수행 → 품질 통제

## 데이터 적재 및 저장

### 분산 파일 시스템
1) HDFS 
	- 슬레이브를 관리하는 마스터 노드와 데이터를 처리하는 슬레이브 노드로 구성
	- 데이터를 64MB의 여러 블록으로 분산 저장
	- 분산 처리로 시스템의 과부하 및 병목현상 해소
	- 오픈소스이며 무료 사용 가능

2) GFS
	- 구글에서 설계한 분산 파일 시스템
	- 마스터(관리 및 통제), 청크 서버(물리적 데이터 저장), 클라이언트로 구성

3) 그 외 파일 시스템
	- Ceph, 아마존 S3 등

### 데이터베이스
1) 관계형 데이터베이스 : 정형 데이터 처리 및 무결성 보장(MySQL, MariaDB, Oracle)
	- 무결성 : 데이터의 정확성과 일관성을 유지하는 특성

2) NoSQL : 비정형 데이터 처리, 높은 확장성과 가용성
	- Key-value : 키와 값의 쌍으로 데이터를 저장 (예: Redis)
	- 열 : 데이터가 열 기반으로 저장 (예: HBase)
	- 문서 : 문서 형태로 데이터 저장 (예: MongoDB)
	- 그래프 : 노드와 엣지로 관계를 표현하여 데이터 저장 (예: Neo4j)

### 데이터 웨어하우스
1) 데이터 웨어하우스의 특징
	- 주체 지향성 : 특정 주제 중심으로 데이터 구성
	- 데이터 통합 : 여러 소스에서 데이터를 통합하여 제공
	- 시계열성 : 시간 흐름에 따라 데이터 변화 저장
	- 비휘발성 : 한번 저장된 데이터는 변경되지 않음

2) 데이터 웨어하우스 구성요소
	- ETL: 추출, 변환, 적재 프로세스
	- ODS: 운영 데이터 저장소로 즉각적인 분석 지원

3) 데이터 마트
	- 데이터 웨어하우스의 특정 분야 또는 목적을 위해 구축된 소규모 웨어하우스

4) 데이터 레이크
	- 비정형 데이터를 원본 형태로 저장하여 데이터 분석 및 학습과 연계하여 처리
